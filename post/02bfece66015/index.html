<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CS231n/EECS598 学习笔记（一） Lecture 1 - 4 | Cyrus' Blog</title><meta name="author" content="cyrus28214"><meta name="copyright" content="cyrus28214"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="课程介绍Deep Learning for Computer Vision是一门介绍深度学习在计算机视觉中的应用的课程，本课程中介绍了如何实现、训练和调试自己的神经网络，并详细展示了计算机视觉的前沿研究。课程中还包括一些训练和微调视觉识别任务网络的实用工程技巧。CS231n是斯坦福大学的版本，由于这门课程在网络上最新的版本是2017年比较早，因此我选择了教学大纲基本相同，但有额外扩充内容的另一门课">
<meta property="og:type" content="article">
<meta property="og:title" content="CS231n&#x2F;EECS598 学习笔记（一） Lecture 1 - 4">
<meta property="og:url" content="https://cyrus28214.top/post/02bfece66015/index.html">
<meta property="og:site_name" content="Cyrus&#39; Blog">
<meta property="og:description" content="课程介绍Deep Learning for Computer Vision是一门介绍深度学习在计算机视觉中的应用的课程，本课程中介绍了如何实现、训练和调试自己的神经网络，并详细展示了计算机视觉的前沿研究。课程中还包括一些训练和微调视觉识别任务网络的实用工程技巧。CS231n是斯坦福大学的版本，由于这门课程在网络上最新的版本是2017年比较早，因此我选择了教学大纲基本相同，但有额外扩充内容的另一门课">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cyrus28214.top/images/eecs598/ImageNet.png">
<meta property="article:published_time" content="2024-02-25T12:19:08.000Z">
<meta property="article:modified_time" content="2024-03-25T14:46:08.000Z">
<meta property="article:author" content="cyrus28214">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="CV">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="CS231n">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cyrus28214.top/images/eecs598/ImageNet.png"><link rel="shortcut icon" href="/images/icon32.png"><link rel="canonical" href="https://cyrus28214.top/post/02bfece66015/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CS231n/EECS598 学习笔记（一） Lecture 1 - 4',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-25 22:46:08'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/icon512.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">55</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">90</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/lab/"><i class="fa-fw fas fa-flask"></i><span> 实验室</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cyrus28214.top/images/eecs598/ImageNet.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Cyrus' Blog"><span class="site-name">Cyrus' Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/lab/"><i class="fa-fw fas fa-flask"></i><span> 实验室</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CS231n/EECS598 学习笔记（一） Lecture 1 - 4</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-25T12:19:08.000Z" title="发表于 2024-02-25 20:19:08">2024-02-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-25T14:46:08.000Z" title="更新于 2024-03-25 22:46:08">2024-03-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/DS-AI/">DS&amp;AI</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CS231n/EECS598 学习笔记（一） Lecture 1 - 4"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="课程介绍"><a href="#课程介绍" class="headerlink" title="课程介绍"></a>课程介绍</h2><p>Deep Learning for Computer Vision是一门介绍深度学习在计算机视觉中的应用的课程，本课程中介绍了如何实现、训练和调试自己的神经网络，并详细展示了计算机视觉的前沿研究。课程中还包括一些训练和微调视觉识别任务网络的实用工程技巧。CS231n是斯坦福大学的版本，由于这门课程在网络上最新的版本是2017年比较早，因此我选择了教学大纲基本相同，但有额外扩充内容的另一门课程，密歇根大学的EECS498&#x2F;598，这门课在网上公开的最新版本是FA2019。</p>
<p>课程相关链接：</p>
<p><a target="_blank" rel="noopener" href="https://web.archive.org/web/20230328031120/https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2020/">https://web.archive.org/web/20230328031120/https://web.eecs.umich.edu/~justincj&#x2F;teaching&#x2F;eecs498&#x2F;FA2020&#x2F;</a></p>
<p><a target="_blank" rel="noopener" href="http://cs231n.stanford.edu/schedule.html">http://cs231n.stanford.edu/schedule.html</a></p>
<span id="more"></span>

<h2 id="课后作业答案"><a href="#课后作业答案" class="headerlink" title="课后作业答案"></a>课后作业答案</h2><p>下面是我的作业解答链接</p>
<p><a target="_blank" rel="noopener" href="https://github.com/cyrus28214/EECS598-solutions">https://github.com/cyrus28214/EECS598-solutions</a></p>
<h2 id="Lecture-1"><a href="#Lecture-1" class="headerlink" title="Lecture 1"></a>Lecture 1</h2><p>对计算机视觉做了简单的引入，主要介绍了计算机视觉的发展历史。</p>
<p><img src="https://cyrus28214.top/images/eecs598/venn.png" alt="各种术语的范围辨析"></p>
<p>这篇CV领域著名的论文SIFT完成了recognition in matching的任务。</p>
<p><img src="https://cyrus28214.top/images/eecs598/SIFT.png" alt="CV史上比较重要的突破，完成了matching的任务"></p>
<p>人脸识别方面的技术得到了迅速的商业化。</p>
<p><img src="https://cyrus28214.top/images/eecs598/face.png" alt="人脸识别"></p>
<p>ImageNet项目作为一个图像数据集，其数据规模达到了惊人的1400万张图片，也成为了计算机视觉领域算法效果的重要检验标准。随后，AlexNet将深度学习引入计算机视觉领域，大大地降低了错误率，并开启了深度学习在CV领域的广泛应用。</p>
<p><img src="https://cyrus28214.top/images/eecs598/ImageNet.png" alt="ImageNet &amp; AlexNet"></p>
<p>GPU的发展极大地增加了计算机视觉的计算能力。结合深度学习的模型，使计算机视觉领域得到突破。</p>
<p><img src="https://cyrus28214.top/images/eecs598/GPU.png" alt="GPU的发展"></p>
<p>Justin教授认为，计算机视觉领域的发展，主要取决于三个因素：算法、数据、计算。这三个方面对应上面提到的深度学习、ImageNet、GPU for deep learning。</p>
<p><img src="https://cyrus28214.top/images/eecs598/3factors.png" alt="三种因素"></p>
<p>Lecture 1剩下的内容就是一些课程大纲的介绍，就不提了。</p>
<h2 id="Lecture-2"><a href="#Lecture-2" class="headerlink" title="Lecture 2"></a>Lecture 2</h2><p>Lecture 2首先使用了猫作为例子来阐述图片分类任务有哪些挑战，这个例子非常令人印象深刻，我看过的一些博客文章里，也引用了这个“CS231n的猫”的例子。</p>
<p>图片分类任务的挑战主要包括：</p>
<ol>
<li>所谓的Semantic Gap，我看了一下，大致的意思就是说人类可以一眼看出来图片上是个猫，但是在计算机眼中，图片只是一堆数字组成的点阵，而且人类没法设计一个精确的算法告诉计算机什么是猫，怎么识别猫。</li>
<li>不同的视角：即使是同一只猫，在不同的视角下拍摄的图片也会大不相同。</li>
<li>光照：光照也可以是识别的对象发生很大的改变。</li>
<li>背景干扰：不同的背景可能会干扰模型的识别结果。</li>
<li>Occlusion：有时图片里的猫不会是一个完整的个体，而是有部分被遮挡了。</li>
<li>Deformation：物体会发生形变，譬如猫有不同的姿态，站着、躺着、坐着……</li>
<li>Intraclass variation：猫的品种不同，它们有不同的颜色、花纹、大小等。给计算机视任务造成了困难。</li>
<li>Context：比如说，猫可能与场景中的其他物体有关系，比如猫的身上有栏杆投下的影子，使得猫看起来像一只老虎，我们的算法甚至还需要理解现实世界的一些规律。</li>
</ol>
<p><img src="https://cyrus28214.top/images/eecs598/occlusion.png" alt="occlusion"></p>
<p><img src="https://cyrus28214.top/images/eecs598/deformation.png" alt="deformation"></p>
<p><img src="https://cyrus28214.top/images/eecs598/context.png" alt="context"></p>
<p>要解决上面的问题，可以使用数据驱动（Data-Driven）的算法，这样你无需语义化地告诉计算机什么是猫，只需要提供大量的猫的图片，让计算机自己学习什么是猫。</p>
<p>这种方法同时带来了另一个好处：<strong>可重用</strong>，也就是说，你使用猫的图片训练模型，模型就能识别猫，使用星系的图片训练模型，模型就能分辨星系的种类。你无需为各种计算机视觉任务开发不同的模型。</p>
<p><img src="https://cyrus28214.top/images/eecs598/data-driven.png" alt="data-driven"></p>
<h3 id="KNN算法（K-Nearest-Neighbor-Classifier）"><a href="#KNN算法（K-Nearest-Neighbor-Classifier）" class="headerlink" title="KNN算法（K-Nearest Neighbor Classifier）"></a>KNN算法（K-Nearest Neighbor Classifier）</h3><p>KNN算法是一种非常简单的数据驱动算法，它非常容易实现。KNN并不是一个进行图像分类的理想算法（但是经常和其他算法结合，达到更好的效果），课程使用KNN应该是为了以此为例，解释数据驱动的算法。</p>
<p>KNN的基本思想是：我们首先将训练的图片保存在模型中。给定一张新的图片，我们首先计算这张图片与所有训练图片的距离，然后选择距离最近的K张图片，这K张图片中，出现次数最多的类别，就是这张图片的类别。</p>
<p>要计算图片之间的距离，首先你要把图片变成一个一维向量，比如一张<code>(H, W, C)</code>的图片（H、W、C分别代表高度、宽度、通道），就可以变成一个<code>(H*W*C)</code>的向量。然后，我们就可以计算任意两张图片之间的距离了。</p>
<p>距离函数有多种选择，如L1距离（曼哈顿距离）、L2距离（欧式距离）。公式如下：</p>
<p>$$\begin{aligned}<br>d_1(I_1, I_2) &amp;&#x3D; \sum\limits_p |I_1^p - I_2^p| \<br>d_2(I_1, I_2) &amp;&#x3D; \sqrt{\sum\limits_p (I_1^p - I_2^p)^2}<br>\end{aligned}$$</p>
<p>从图中可以发现，L1距离实现的KNN算法的特点是决策边界都是横线、竖线或45°斜线，而L2距离实现的KNN算法的决策边界可以是任何直线。</p>
<p><img src="https://cyrus28214.top/images/eecs598/knn.png" alt="knn"></p>
<p>像$k$这样，不是通过模型训练得到，而是提前设置好的参数，被称为<strong>超参数（Hyperparameter）</strong>。</p>
<h3 id="训练集和测试集（Training-Set-and-Testing-Set）"><a href="#训练集和测试集（Training-Set-and-Testing-Set）" class="headerlink" title="训练集和测试集（Training Set and Testing Set）"></a>训练集和测试集（Training Set and Testing Set）</h3><p>训练集和测试集是两个非常重要的概念。训练集用于训练模型，测试集用于评估模型的性能。</p>
<p>为什么要分训练集和测试集呢，因为你的模型有可能在训练集上表现很好，但是在测试集上表现不好，这种现象被称为过拟合（Overfitting）。</p>
<p>假如你将所有数据都作为训练集，那么你将无法评估你的模型到底在从未见过的数据集上表现如何。</p>
<p>具体到KNN算法来说，假如你选取$k&#x3D;1$，并使用同一份数据进行训练和测试，那么结果会怎么样？</p>
<p>答案是你的模型将永远是100%正确，你无法评估模型的效果如何。</p>
<h3 id="交叉验证（Cross-Validation）"><a href="#交叉验证（Cross-Validation）" class="headerlink" title="交叉验证（Cross Validation）"></a>交叉验证（Cross Validation）</h3><p>交叉验证是用来评估模型性能的常用方法。将数据集分成n份，每次选择其中一份作为验证集（Validation set），其他n-1份作为训练集，然后训练模型，最后在测试集上模型的性能。交叉验证可以防止因为分割数据方式不同引起的误差。</p>
<h3 id="设置超参数"><a href="#设置超参数" class="headerlink" title="设置超参数"></a>设置超参数</h3><p>KNN中有一个参数$k$，代表选择最近邻的个数。$k$的取值不同，KNN算法的效果也不同。</p>
<p>我们可以用交叉验证来设置超参数$k$，我们不能故意选择一个使得模型在测试集上表现很好的$k$。我们只能在最后使用测试集评估性能，不能人为地引入误差使得模型在测试集上表现很好。</p>
<p>在我们的KNN模型中，我们设置不同的$k&#x3D;1,2,3,\dots$，然后在验证集上测试模型的效果，得出了表现最好的$k\approx 7$，然后用$k&#x3D;7$的模型在整个训练集上训练，最后用测试集评估结果。</p>
<p><img src="https://cyrus28214.top/images/eecs598/distance.png" alt="用不同的距离函数实现的KNN算法"></p>
<p><em>按照我的理解，$k$越小模型越倾向于过拟合，而$k$过大的话模型容易欠拟合。</em></p>
<p><img src="https://cyrus28214.top/images/eecs598/settinghyperparameters.png" alt="设置超参数"></p>
<h3 id="KNN的缺陷"><a href="#KNN的缺陷" class="headerlink" title="KNN的缺陷"></a>KNN的缺陷</h3><ul>
<li>图片之间的距离并不能很好的衡量图片的相似程度，比如只是对图片主体进行平移就会使图片距离变得很远。</li>
<li>计算的复杂性，课程中提到了<strong>Curse of dimensionality</strong>，假如我们在低维空间内使用足够多的数据点覆盖空间，KNN算法的确能得到不错的效果，然而随着模型维度的升高，我们需要的数据点个数将以指数增加。图像识别任务通常需要使用非常高（成千上万）个维度。假如我们使用$4$个点覆盖一维坐标轴，那么要达到相似的数据密度，一个平面就需要$4^2$个点，一个$10000$维的空间就需要$4^{10000}$个点！这是无法接受的</li>
<li>KNN的训练很快而计算很慢，KNN的训练只需要保存所有数据，如果按照传递引用算就是$O(1)$，而计算新的数据的分类需要计算它与所有点的距离，这是$O(ND)$的（$N$是训练数据个数，$D$是维度）。这与我们的希望相反，我们更偏爱训练慢而计算快的模型（下一节课就会有这种模型）。</li>
</ul>
<h2 id="Lecture-3"><a href="#Lecture-3" class="headerlink" title="Lecture 3"></a>Lecture 3</h2><h3 id="线性分类器"><a href="#线性分类器" class="headerlink" title="线性分类器"></a>线性分类器</h3><p>这节课介绍了一个新的模型：<strong>线性分类器（Linear Classifier）</strong>。</p>
<p>线性分类器就是这样一个简单的模型：</p>
<p>$$<br>f(x, W) &#x3D; Wx<br>$$</p>
<p>其中$W$是一个权重矩阵，$x$是输入的图片。</p>
<p>这个模型重要不是因为它效果很好，而是因为这个简单的模型是完成后续的复杂模型的“积木”。</p>
<p>为了理解这个重要的模型，这节课提供了三种视角：</p>
<p><img src="https://cyrus28214.top/images/eecs598/3viewpoints.png" alt="三种视角"></p>
<h4 id="代数视角"><a href="#代数视角" class="headerlink" title="代数视角"></a>代数视角</h4><p><img src="https://cyrus28214.top/images/eecs598/algebraic.png" alt="代数视角"></p>
<p>从代数视角看，线性分类器仅仅是把图片乘以一个矩阵$W$，然后加上一个偏置项$b$，一切操作都是线性的，这意味着将图片乘以一个常数，结果也将线性地变化。对于分类图片，这个性质比较奇怪，但是明白这个有利于我们更好地理解线性分类器。</p>
<h4 id="可视化视角"><a href="#可视化视角" class="headerlink" title="可视化视角"></a>可视化视角</h4><p><img src="https://cyrus28214.top/images/eecs598/visual.png" alt="可视化视角"></p>
<p>从可视化的视角来看，每一种类别都对应着一个不同的“模版”，我们可以把图片投影到这些模版上，和模版越接近的就会被分到相应的类别。</p>
<h4 id="几何视角"><a href="#几何视角" class="headerlink" title="几何视角"></a>几何视角</h4><p><img src="https://cyrus28214.top/images/eecs598/geometry.png" alt="几何视角"></p>
<p>从几何的视角来看，线性分类器就是一个超平面，面向超平面的方向越往前就越属于某个类别。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>损失函数（Loss Function）是衡量模型预测结果与真实结果的差距的函数。损失越低，意味着模型的预测效果越好。</p>
<h4 id="SVM-Loss"><a href="#SVM-Loss" class="headerlink" title="SVM Loss"></a>SVM Loss</h4><p>SVM Loss会惩罚错误的分类，和不自信的正确分类。</p>
<p>$$L_i &#x3D; \sum_{j\neq y_i} \max(0, s_j - s_{y_i} + 1)$$</p>
<p>总的Loss是所有$L_i$之和</p>
<h4 id="正则化（Regularization）"><a href="#正则化（Regularization）" class="headerlink" title="正则化（Regularization）"></a>正则化（Regularization）</h4><p>正则化可以防止过拟合。正则化向损失函数中加入一个正则化项，惩罚模型中过大的参数：</p>
<p>$$L(W) &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N L_i + \lambda R(W)$$</p>
<p>其中$R(W)$是正则化项，$\lambda$是正则化系数。</p>
<p>L2正则化：</p>
<p>$$R(W) &#x3D; \sum_{i,j} W_{i,j}^2$$</p>
<p>L1正则化：</p>
<p>$$R(W) &#x3D; \sum_{i,j} |W_{i,j}|$$</p>
<p>Elastic Net：结合使用L1和L2正则化：</p>
<p>$$R(W) &#x3D; \sum_{i,j} \beta W_{i,j}^2 + |W_{i,j}|$$</p>
<p>更多方案包括Dropout、Batch Normalization等。</p>
<p>正则化更喜欢简单的模型，$W$里面如果有绝对值很大的系数，$R(W)$就会变大，这使得模型在获得更好的表现的同时采用更简单的方法，避免了过拟合。</p>
<h4 id="交叉熵（Cross-Entropy）"><a href="#交叉熵（Cross-Entropy）" class="headerlink" title="交叉熵（Cross Entropy）"></a>交叉熵（Cross Entropy）</h4><p>交叉熵将模型的预测结果转换为概率分布，然后计算真实结果的对数似然。</p>
<p>$$P(Y&#x3D;k|X&#x3D;x_i) &#x3D; \frac{e^{f(x_i, W)}}{\sum_{j&#x3D;1} e^{f(x_j, W)}}$$</p>
<p>$$L_i &#x3D; -\log P(Y&#x3D;y_i|X&#x3D;x_i)$$</p>
<h2 id="Lecture-4"><a href="#Lecture-4" class="headerlink" title="Lecture 4"></a>Lecture 4</h2><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>优化（Optimization）是指找到使得损失函数尽量小的模型参数。</p>
<p>$$ W^* &#x3D; \arg_W \min L(W) $$</p>
<h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>如果把损失函数看作是一座山脉，如果你要下山，你会每次都沿着高度降低的方向走，这就是梯度下降的思想。</p>
<p>梯度下降法计算出损失函数在当前参数的梯度，然后沿着<strong>负梯度</strong>的方向<strong>走一小步</strong>，然后更新当前参数，重复这个过程。</p>
<p>这里写的是负梯度而不是梯度，是因为数学上，梯度的定义是</p>
<p>$$\nabla f(\boldsymbol{x}) &#x3D; \left(\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \dots, \frac{\partial f}{\partial x_n}\right)$$</p>
<p>这是一个矢量，矢量的方向指向$f$函数增长最快的方向，而反过来，负梯度的方向就是$f$函数减小最快的方向。</p>
<h5 id="数值方法和分析方法"><a href="#数值方法和分析方法" class="headerlink" title="数值方法和分析方法"></a>数值方法和分析方法</h5><p>为了精度和效率的考虑，我们应该使用analytic的方法而不是numerical的方法来计算梯度。像PyTorch这样的深度学习框架都有Autograd的功能，可以方便地自动计算梯度，但有时你也需要手写梯度计算的代码。</p>
<p>Numerical gradient精度又低计算速度又慢，最好不要使用。例外是gradient check，你可以用数值的方法来验证analytic梯度计算的正确性。这个也不需要你手写，<code>torch.autograd.gradcheck</code>专门用来干这个。</p>
<h5 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h5><p>学习率（Learning Rate）是梯度下降法中一个重要的超参数。学习率决定了模型参数更新的步长，如果学习率过大，模型可能无法收敛到最优解，如果学习率过小，模型收敛速度会很慢。</p>
<p>我们上面提到，梯度下降法就是每次向负梯度的方向走<strong>一小步</strong>，学习率决定了这一步有多长。</p>
<p>$$ W^* &#x3D; W - \eta \nabla L(W) $$</p>
<p>其中$\eta$是学习率。在训练模型的时候我们会反复应用这一更新规则，直到损失函数下降到可以接受。</p>
<h4 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h4><p>$$ \nabla L(W) &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N \nabla L(x_i, y_i, W) + \lambda \nabla R(W) $$</p>
<p>$N$是我们训练集的大小，当$N$比较小的时候，我们可以一次性计算所有梯度。但是当$N$比较大的时候，一次性计算梯度会是比较昂贵的，（比如显存不够用之类的），这时我们可以分 batch计算梯度,每次只送入一部分数据计算梯度，然后更新参数。</p>
<p>这就引入了一个新的超参数<code>batch_size</code>。<span style="font-size: 0.8em; color: #999;">超参数越来越多了，终于有调参炼丹的感觉了（bushi</span></p>
<p><code>batch_size</code>的参考取值差不多是32、64、128、256这个大小。</p>
<h4 id="随机梯度下降（SGD）"><a href="#随机梯度下降（SGD）" class="headerlink" title="随机梯度下降（SGD）"></a>随机梯度下降（SGD）</h4><p>随机梯度下降没什么难理解的，就是每次从训练集中随机sample一个batch来梯度下降。</p>
<h4 id="SGD-Momentum"><a href="#SGD-Momentum" class="headerlink" title="SGD + Momentum"></a>SGD + Momentum</h4><p>SGD有一些问题。</p>
<h5 id="Zigzag"><a href="#Zigzag" class="headerlink" title="Zigzag"></a>Zigzag</h5><p>由于SGD每次选择梯度最低的方向，如果某个维度上梯度下降很快，那么其他维度上的步长就会很小，导致算法走出zigzag的形状。</p>
<p><img src="https://cyrus28214.top/images/eecs598/problems_SGD.png"></p>
<p>关于图片底部这句话，想要理解它需要一定的线性代数基础，如果不懂的话跳过也没关系。</p>
<blockquote>
<p>Aside: Loss function has high <strong>condition number</strong>: ratio of largest to smallest eigenvalue of Hessian matrix is large.</p>
</blockquote>
<p>下面是我个人的一点理解：</p>
<blockquote>
<p>Hessian矩阵可以类比成是一元函数的二阶导。直观理解的话，Hessian矩阵可以描述函数在某一点处弯曲的形状。</p>
<p>矩阵的条件数可以衡量矩阵有多“扁”，比如正交矩阵你就当做是一个圆，它每一个方向上都一样长，它的条件数是1。一个条件数很大的矩阵可以看成一个很扁的椭圆，它最显著的维度和最不显著的维度相差很大。</p>
<p>Hessian矩阵的条件数很大的话，说明loss funtion在某个维度上面呈现陡峭的“V”形，函数的梯度来回变化，导致算法走出zigzag的形状。</p>
</blockquote>
<h5 id="鞍点"><a href="#鞍点" class="headerlink" title="鞍点"></a>鞍点</h5><p>鞍点（Saddle point）就是长这样的点：</p>
<p><img src="https://cyrus28214.top/images/eecs598/saddle_point.png"></p>
<p>鞍点并不是极小值，但是鞍点的梯度却是0，按照之前的算法，零梯度会让我们卡在鞍点动不了。</p>
<p>顺带一提，Hessian矩阵也可以用来判断鞍点，如果$\nabla f(\boldsymbol{x})&#x3D;0$，且$\mathbf{H}$是不定矩阵，即特征值有正有负，那么$\boldsymbol{x}$就是鞍点。（当Hessian矩阵有零特征值的时候这个判断失效，需要展开到三阶或以上）</p>
<h5 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><p>这两个问题都可以通过引入动能项来解决。</p>
<p>$$\begin{align*}<br>v_{t+1} &amp;&#x3D; \rho v_t - \alpha \nabla L(x_t)\<br>x_{t+1} &amp;&#x3D; x_t + v_{t+1}<br>\end{align*}$$</p>
<p><em>这个方程有很多种写法</em>，如果见到了不一样的形式不用奇怪，都是对的</p>
<p>$v$就好像给了这个点一个速度，让它记住历史的梯度，$\rho$用来模拟摩擦，让速度衰减，然后每次用梯度更新速度，再用速度更新参数。</p>
<p>引入动能项可以解决zigzag问题，因为两个相反方向上的梯度会在动能项里相互抵消，让模型专注于其他维度。</p>
<p>也可以解决鞍点问题，模型走到鞍点的时候还有动能，不会停滞不前。</p>
<p>一举两得！</p>
<h4 id="Nestrov-Momentum"><a href="#Nestrov-Momentum" class="headerlink" title="Nestrov Momentum"></a>Nestrov Momentum</h4><p>Mestrov Momentum是SGD + Momentum的变种，它用了“look ahead”的思想，使用$x_t+\rho v_t$而非$x_t$处的梯度。</p>
<p><img src="https://cyrus28214.top/images/eecs598/nestrov.png"></p>
<p>$$\begin{align*}<br>v_{t+1} &amp;&#x3D; \rho v_t - \alpha \nabla L(x_t + \rho v_t)\<br>x_{t+1} &amp;&#x3D; x_t + v_{t+1}<br>\end{align*}$$</p>
<p>关于这个算法我查阅了相关资料，之所以这样做有更好的效果，是因为这种做法会包含函数的二阶项，允许更加精细的梯度下降（但不是真正的二阶近似）。具体的数学推导比较冗长，有兴趣可以自行了解。</p>
<h4 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h4><p>Adagrad是一种自适应学习率的方法，它会动态调整学习率。当梯度比较平坦的时候走得快一点，梯度比较陡峭的时候走得慢一点。</p>
<h4 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h4><p>RMSprop是Adagrad的变种，增加了Decay。</p>
<h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><p>Adam≈RMSprop + Momentum。Adam是实践中非常常用，效果也很不错的Optimizer。</p>
<h4 id="L-BFGS"><a href="#L-BFGS" class="headerlink" title="L-BFGS"></a>L-BFGS</h4><p>到目前为止我们的优化算法都是一阶近似，而BFGS算法使用了二阶近似，<strong>当一次性使用整个训练集做full batch的时候效果非常好</strong>，但是当使用mini-batch的时候效果不怎么好。这比较好理解，因为用到了二阶项，如果batch太小的话，高阶项比低阶项更容易出现偏差。</p>
<p>缺点是复杂度是$O(n^3)$的，一般只用于小数据集。</p>
<p>L-BFGS是BFGS的内存优化版本。</p>
<h4 id="In-practice"><a href="#In-practice" class="headerlink" title="In practice"></a>In practice</h4><ul>
<li><strong>Adam</strong>是一个很好的默认选择，在大多数情况下效果不错。</li>
<li><strong>SGD + Momentum</strong>有时比Adam好，但是需要很多玄学调参。</li>
<li>如果训练集比较小，你的机器能跑$O(n^3)$，试试<strong>L-BFGS</strong>吧。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://cyrus28214.top">cyrus28214</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://cyrus28214.top/post/02bfece66015/">https://cyrus28214.top/post/02bfece66015/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://cyrus28214.top" target="_blank">Cyrus' Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="post-meta__tags" href="/tags/CV/">CV</a><a class="post-meta__tags" href="/tags/ML/">ML</a><a class="post-meta__tags" href="/tags/CS231n/">CS231n</a></div><div class="post_share"><div class="social-share" data-image="https://cyrus28214.top/images/eecs598/ImageNet.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/images/reward/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/images/reward/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/post/29fec64214ce/" title="学会Emmet语法，告别手打HTML和CSS"><img class="cover" src="/images/emmet.gif" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">学会Emmet语法，告别手打HTML和CSS</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/post/5941ab677246/" title="半加器、全加器与超前进位加法器"><img class="cover" src="https://cyrus28214.top/images/s/649e549d1ddac507cce6a707.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-30</div><div class="title">半加器、全加器与超前进位加法器</div></div></a></div><div><a href="/post/0e8d2ef41193/" title="SQL学习笔记（一）安装SQLite"><img class="cover" src="https://cyrus28214.top/images/s/651985d9c458853aefbe98ea.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-02</div><div class="title">SQL学习笔记（一）安装SQLite</div></div></a></div><div><a href="/post/3f6aa83f99ff/" title="SQL学习笔记（二）创建一个表"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-02</div><div class="title">SQL学习笔记（二）创建一个表</div></div></a></div><div><a href="/post/6495a78f89c0/" title="SQL学习笔记（三）基本查询语句"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-03</div><div class="title">SQL学习笔记（三）基本查询语句</div></div></a></div><div><a href="/post/04355221d8d3/" title="SQL学习笔记（四）条件与分组语句"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-04</div><div class="title">SQL学习笔记（四）条件与分组语句</div></div></a></div><div><a href="/post/5ac6b37ce725/" title="SQL学习笔记（五）插入、更新与删除"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-06</div><div class="title">SQL学习笔记（五）插入、更新与删除</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/icon512.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">cyrus28214</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">55</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">90</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><a id="card-info-btn" href="/images/social/WeChatOfficial.jpg"><i class="fab fa-weixin"></i><span>关注微信公众号</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/cyrus28214" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:cyrus28214@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="/images/social/QQ.jpg" target="_blank" title="QQ"><i class="fab fa-qq" style="color: #259ce1;"></i></a><a class="social-icon" href="/images/social/WeChat.jpg" target="_blank" title="微信"><i class="fab fa-weixin" style="color: #08c061;"></i></a><a class="social-icon" href="https://www.zhihu.com/people/cyrus28214" target="_blank" title="知乎"><i class="fab fa-zhihu" style="color: #0080f7;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%BE%E7%A8%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">课程介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%BE%E5%90%8E%E4%BD%9C%E4%B8%9A%E7%AD%94%E6%A1%88"><span class="toc-number">2.</span> <span class="toc-text">课后作业答案</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lecture-1"><span class="toc-number">3.</span> <span class="toc-text">Lecture 1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lecture-2"><span class="toc-number">4.</span> <span class="toc-text">Lecture 2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#KNN%E7%AE%97%E6%B3%95%EF%BC%88K-Nearest-Neighbor-Classifier%EF%BC%89"><span class="toc-number">4.1.</span> <span class="toc-text">KNN算法（K-Nearest Neighbor Classifier）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%EF%BC%88Training-Set-and-Testing-Set%EF%BC%89"><span class="toc-number">4.2.</span> <span class="toc-text">训练集和测试集（Training Set and Testing Set）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%EF%BC%88Cross-Validation%EF%BC%89"><span class="toc-number">4.3.</span> <span class="toc-text">交叉验证（Cross Validation）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E8%B6%85%E5%8F%82%E6%95%B0"><span class="toc-number">4.4.</span> <span class="toc-text">设置超参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KNN%E7%9A%84%E7%BC%BA%E9%99%B7"><span class="toc-number">4.5.</span> <span class="toc-text">KNN的缺陷</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lecture-3"><span class="toc-number">5.</span> <span class="toc-text">Lecture 3</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">5.1.</span> <span class="toc-text">线性分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E6%95%B0%E8%A7%86%E8%A7%92"><span class="toc-number">5.1.1.</span> <span class="toc-text">代数视角</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E8%A7%86%E8%A7%92"><span class="toc-number">5.1.2.</span> <span class="toc-text">可视化视角</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%A0%E4%BD%95%E8%A7%86%E8%A7%92"><span class="toc-number">5.1.3.</span> <span class="toc-text">几何视角</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">5.2.</span> <span class="toc-text">损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SVM-Loss"><span class="toc-number">5.2.1.</span> <span class="toc-text">SVM Loss</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%88Regularization%EF%BC%89"><span class="toc-number">5.2.2.</span> <span class="toc-text">正则化（Regularization）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5%EF%BC%88Cross-Entropy%EF%BC%89"><span class="toc-number">5.2.3.</span> <span class="toc-text">交叉熵（Cross Entropy）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lecture-4"><span class="toc-number">6.</span> <span class="toc-text">Lecture 4</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96"><span class="toc-number">6.1.</span> <span class="toc-text">优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">6.1.1.</span> <span class="toc-text">梯度下降</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E5%80%BC%E6%96%B9%E6%B3%95%E5%92%8C%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95"><span class="toc-number">6.1.1.1.</span> <span class="toc-text">数值方法和分析方法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="toc-number">6.1.1.2.</span> <span class="toc-text">学习率</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Batch"><span class="toc-number">6.1.2.</span> <span class="toc-text">Batch</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88SGD%EF%BC%89"><span class="toc-number">6.1.3.</span> <span class="toc-text">随机梯度下降（SGD）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SGD-Momentum"><span class="toc-number">6.1.4.</span> <span class="toc-text">SGD + Momentum</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Zigzag"><span class="toc-number">6.1.4.1.</span> <span class="toc-text">Zigzag</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9E%8D%E7%82%B9"><span class="toc-number">6.1.4.2.</span> <span class="toc-text">鞍点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">6.1.4.3.</span> <span class="toc-text">解决方案</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Nestrov-Momentum"><span class="toc-number">6.1.5.</span> <span class="toc-text">Nestrov Momentum</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Adagrad"><span class="toc-number">6.1.6.</span> <span class="toc-text">Adagrad</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RMSprop"><span class="toc-number">6.1.7.</span> <span class="toc-text">RMSprop</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Adam"><span class="toc-number">6.1.8.</span> <span class="toc-text">Adam</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#L-BFGS"><span class="toc-number">6.1.9.</span> <span class="toc-text">L-BFGS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#In-practice"><span class="toc-number">6.1.10.</span> <span class="toc-text">In practice</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/02bfece66015/" title="CS231n/EECS598 学习笔记（一） Lecture 1 - 4"><img src="https://cyrus28214.top/images/eecs598/ImageNet.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CS231n/EECS598 学习笔记（一） Lecture 1 - 4"/></a><div class="content"><a class="title" href="/post/02bfece66015/" title="CS231n/EECS598 学习笔记（一） Lecture 1 - 4">CS231n/EECS598 学习笔记（一） Lecture 1 - 4</a><time datetime="2024-02-25T12:19:08.000Z" title="发表于 2024-02-25 20:19:08">2024-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/29fec64214ce/" title="学会Emmet语法，告别手打HTML和CSS"><img src="/images/emmet.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="学会Emmet语法，告别手打HTML和CSS"/></a><div class="content"><a class="title" href="/post/29fec64214ce/" title="学会Emmet语法，告别手打HTML和CSS">学会Emmet语法，告别手打HTML和CSS</a><time datetime="2024-02-07T10:50:44.000Z" title="发表于 2024-02-07 18:50:44">2024-02-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/post/deeeefb148a9/" title="用Java中的Record（记录类）简化代码">用Java中的Record（记录类）简化代码</a><time datetime="2024-01-22T04:11:16.000Z" title="发表于 2024-01-22 12:11:16">2024-01-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/303a9aabf405/" title="OSI七层网络模型"><img src="https://cyrus28214.top/images/s/6545ecacc458853aef62eca9.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OSI七层网络模型"/></a><div class="content"><a class="title" href="/post/303a9aabf405/" title="OSI七层网络模型">OSI七层网络模型</a><time datetime="2024-01-18T16:00:00.000Z" title="发表于 2024-01-19 00:00:00">2024-01-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/7e6546e6c327/" title="理解Cookie、Session和Token"><img src="https://cyrus28214.top/images/set-cookie.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="理解Cookie、Session和Token"/></a><div class="content"><a class="title" href="/post/7e6546e6c327/" title="理解Cookie、Session和Token">理解Cookie、Session和Token</a><time datetime="2024-01-17T14:38:04.000Z" title="发表于 2024-01-17 22:38:04">2024-01-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By cyrus28214</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(()=>{
  const getGiscusTheme = theme => {
    return theme === 'dark' ? 'dark' : 'light'
  }

  const loadGiscus = () => {
    const config = Object.assign({
      src: 'https://giscus.app/client.js',
      'data-repo': 'cyrus28214/giscus',
      'data-repo-id': 'R_kgDOLnfx3Q',
      'data-category-id': 'DIC_kwDOLnfx3c4CeVrb',
      'data-mapping': 'pathname',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true
    },null)

    const ele = document.createElement('script')
    for (let key in config) {
      ele.setAttribute(key, config[key])
    }
    document.getElementById('giscus-wrap').appendChild(ele)
  }

  const changeGiscusTheme = theme => {
    const sendMessage = message => {
      const iframe = document.querySelector('iframe.giscus-frame')
      if (!iframe) return
      iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app')
    }

    sendMessage({
      setConfig: {
        theme: getGiscusTheme(theme)
      }
    });
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment= loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>